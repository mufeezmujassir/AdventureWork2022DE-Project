
---

# ğŸš€ AdventureWorks Azure Data Engineering Project

End-to-End Modern Data Platform using Azure Data Factory, Data Lake, Databricks, Synapse & Power BI

---

## ğŸ“Œ **Project Overview**

This project demonstrates a complete **end-to-end data engineering solution** using the **AdventureWorksLT2022** dataset.
The architecture follows the **Medallion Lakehouse approach** (Bronze â†’ Silver â†’ Gold) for scalable, secure, and analytics-ready data processing.

The system automates ingestion, transformation, storage, analysis, and visualization using Azure cloud services.

---

## ğŸ—ï¸ **Architecture Diagram**

Pipeline flow:

On-Prem SQL â†’ Azure Data Factory â†’ Azure Data Lake (Bronze â†’ Silver â†’ Gold) â†’ Azure Databricks â†’ Azure Synapse Analytics â†’ Power BI
Security: Azure AD + Key Vault

---

## ğŸ¯ **Objectives**

âœ” Ingest data from On-Prem SQL database
âœ” Perform ELT transformations using Azure Databricks
âœ” Store and manage data using Delta Lake (Bronze, Silver, Gold)
âœ” Build Serverless SQL Views in Synapse
âœ” Visualize results with Power BI reports
âœ” Use Key Vault and AAD for secure authentication
âœ” Automate pipelines using ADF scheduled triggers

---

# ğŸ§° **Tech Stack**

### **Azure Services**

* Azure Data Factory (ADF)
* Azure Data Lake Storage Gen2 (ADLS)
* Azure Databricks
* Azure Synapse Serverless SQL
* Azure Key Vault
* Azure Active Directory (AAD)
* Power BI

### **Languages & Tools**

* PySpark
* SQL
* Delta Lake
* Power BI Desktop

---

# ğŸ› ï¸ **Solution Workflow**

## **1ï¸âƒ£ Data Ingestion â€” Bronze Layer (Raw)**

**Azure Data Factory** pulls data from:

* On-Prem SQL Database
  â via Self-Hosted IR

Data is copied into:
`abfss://bronze@<datalake>.dfs.core.windows.net/AdventureWorksLT/`

ADF Pipeline features:

* Copy Activity
* Parameterized pipelines
* Scheduled trigger for daily ingestion

---

## **2ï¸âƒ£ Data Transformation â€” Silver Layer (Cleaned)**

Processed using **Azure Databricks** notebooks.

### Transformations include:

* Converting column names to snake_case
* Type casting
* Null value handling
* Deduplication
* Formatting dates

Silver stored in:
`abfss://silver@<datalake>.dfs.core.windows.net/...`

---

## **3ï¸âƒ£ Curated Business Layer â€” Gold Layer (Aggregated)**

Gold layer stores analytics-ready data, e.g.:

* Customer Sales Summary
* Product Sales Performance
* Yearly and Monthly Sales
* Fact & Dimension models

Gold stored in:
`abfss://gold@<datalake>.dfs.core.windows.net/...`

---

## **4ï¸âƒ£ Synapse Analytics â€” Serverless SQL Views**

A stored procedure is used to dynamically create Serverless SQL Views for each table:

```sql
CREATE OR ALTER PROC CreateSQLServerlessView_gold @ViewName NVARCHAR(100)
AS
BEGIN
DECLARE @statement VARCHAR(MAX)
SET @statement=N'CREATE OR ALTER VIEW ' + @ViewName + ' AS
    SELECT * FROM 
    OPENROWSET(
        BULK ''https://<lake>.dfs.core.windows.net/gold/SalesLT/'+ @ViewName +'/',
        FORMAT = ''DELTA''
    ) AS [result]'

    EXEC (@statement)
END
```

These views connect Power BI directly to ADLS via Delta.

---

## **5ï¸âƒ£ Power BI Reporting**

Power BI connects to **Synapse Serverless** via:

```
Server: <workspace>.sql.azuresynapse.net
Database: gold_db
```

\

# ğŸ” **Security & Governance**

### ğŸ”¹ Azure Active Directory

All access handled using AAD identities.

### ğŸ”¹ Key Vault

Stores:

* SQL credentials
* Service Principal keys
* Databricks secrets

### ğŸ”¹ IAM Roles Used

For **Access Connector** (Databricks to ADLS):

| Role Name                     | Purpose                 |
| ----------------------------- | ----------------------- |
| Storage Blob Data Contributor | Read/Write to Lake      |
| Storage Blob Data Owner       | Optional (full control) |
| Storage Blob Data Reader      | Reading only            |

If you cannot see **Storage Blob Data Contributor**, reason:
â¡ You need **Owner** or **User Access Administrator** role on the subscription/resource.

---

# ğŸ›ï¸ **ADF Pipeline Scheduling**

A Daily Trigger runs:

* Incremental ingestion
* File movement
* Metadata-based execution

Logs and monitoring can be found in ADF Monitor pane.

---



---

# ğŸ“Œ **Key Learnings**

* Implementing the Medallion Architecture
* Secure data ingestion and transformation
* Using Delta Lake for ACID data processing
* Building scalable Serverless SQL layers
* Automating cloud pipelines
* Developing analytics dashboards

---

